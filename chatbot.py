# -*- coding: utf-8 -*-
"""chatbot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NceMibfKaWKfdenBbFxYNAzgor3fSZwb
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from transformers import pipeline

# ----------------------
# ‚úÖ Initial Setup
# ----------------------
st.set_page_config(page_title="üß† Local QA Chatbot", layout="wide")
st.title("ü§ñ Local Knowledge Chatbot")
st.write("Ask any question based on a small general knowledge dataset.")

# ----------------------
# ‚úÖ Load Knowledge Base
# ----------------------
data = [
    "Python is a popular programming language used for web development, data analysis, AI, and more.",
    "Machine learning is a field of AI that allows computers to learn from data without being explicitly programmed.",
    "Paris is the capital of France.",
    "Elon Musk is the founder of SpaceX and Tesla.",
    "India is a country in South Asia with New Delhi as its capital.",
    "Water boils at 100 degrees Celsius at standard atmospheric pressure.",
    "The Great Wall of China is over 13,000 miles long.",
    "The moon is Earth's only natural satellite.",
    "The Pacific Ocean is the largest ocean on Earth.",
    "Photosynthesis is the process by which green plants convert sunlight into energy.",
    "The human heart has four chambers: two atria and two ventricles.",
    "Mount Everest is the tallest mountain in the world.",
    "The Earth revolves around the sun once every 365.25 days.",
    "Light travels at a speed of approximately 299,792 kilometers per second.",
    "The Statue of Liberty was a gift from France to the United States.",
    "Bacteria are single-celled microorganisms that can be both harmful and beneficial.",
    "The internet was invented in the late 20th century.",
    "Electricity is the flow of electric charge through a conductor.",
    "The Taj Mahal is located in Agra, India.",
    "Google was founded by Larry Page and Sergey Brin.",
    "Albert Einstein developed the theory of relativity.",
    "The Amazon Rainforest is the largest tropical rainforest in the world.",
    "Bitcoin is a type of decentralized digital currency.",
    "A galaxy is a system of stars, gas, and dust bound together by gravity.",
    "Venus is the hottest planet in our solar system.",
    "The human body has 206 bones.",
    "HTML stands for HyperText Markup Language.",
    "Shakespeare wrote plays such as Hamlet, Macbeth, and Romeo and Juliet.",
    "COVID-19 is a disease caused by the SARS-CoV-2 virus.",
    "The brain is the control center of the human nervous system."
]

df = pd.DataFrame({"content": data})

# ----------------------
# ‚úÖ Load Models
# ----------------------
@st.cache_resource(show_spinner=False)
def load_models():
    embedder = SentenceTransformer('all-MiniLM-L6-v2')
    qa = pipeline("text2text-generation", model="google/flan-t5-small")
    return embedder, qa

model, qa_model = load_models()

# ----------------------
# ‚úÖ Embed Knowledge Base
# ----------------------
@st.cache_data(show_spinner=False)
def compute_embeddings(texts):
    embeddings = [model.encode(text) for text in texts]
    return np.vstack(embeddings)

doc_embeddings = compute_embeddings(df['content'].tolist())

# ----------------------
# ‚úÖ Similarity Search
# ----------------------
def get_most_similar_doc(query):
    query_embedding = model.encode(query)
    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]
    top_idx = np.argmax(similarities)
    return df.iloc[top_idx]['content']

# ----------------------
# ‚úÖ Chat Interface
# ----------------------
query = st.text_input("üí¨ Ask your question:")

if query:
    with st.spinner("Thinking..."):
        context = get_most_similar_doc(query)
        prompt = f"Context: {context}\nQuestion: {query}"
        response = qa_model(prompt, max_new_tokens=100)[0]['generated_text']
        st.markdown(f"**ü§ñ Answer:** {response.strip()}")

        with st.expander("üîç Matched context"):
            st.info(context)