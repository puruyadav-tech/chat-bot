# -*- coding: utf-8 -*-
"""chatbot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NceMibfKaWKfdenBbFxYNAzgor3fSZwb
"""
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from transformers import pipeline

# üåô Set Streamlit page config
st.set_page_config(page_title="AI ChatBot", page_icon="ü§ñ", layout="centered")

# üñ§ Dark mode styling
st.markdown("""
    <style>
    body {
        background-color: #121212;
        color: #ffffff;
    }
    .stTextInput > div > input {
        background-color: #1f1f1f;
        color: white;
    }
    .message-bubble {
        border-radius: 15px;
        padding: 12px;
        margin: 10px 0;
        display: flex;
        align-items: flex-start;
        gap: 10px;
    }
    .user-bubble {
        background-color: #2a2a2a;
    }
    .bot-bubble {
        background-color: #1e1e1e;
    }
    .avatar {
        width: 32px;
        height: 32px;
        border-radius: 50%;
        margin-top: 5px;
    }
    </style>
""", unsafe_allow_html=True)

# üí¨ Header
st.markdown("""
    <div style='text-align: center; margin-bottom: 20px;'>
        <h1 style='color: white;'>ü§ñ AI ChatBot</h1>
        <p style='color: #cccccc;'>Your intelligent assistant with image generation</p>
    </div>
""", unsafe_allow_html=True)

# üß† Load chatbot data
df = pd.DataFrame({
    "content": [
        "Python is a popular programming language used for web development, data analysis, AI, and more.",
        "Machine learning is a field of AI that allows computers to learn from data without being explicitly programmed.",
        "Paris is the capital of France.",
        "Elon Musk is the founder of SpaceX and Tesla.",
        "India is a country in South Asia with New Delhi as its capital.",
        "Water boils at 100 degrees Celsius at standard atmospheric pressure.",
        "The Great Wall of China is over 13,000 miles long.",
        "The moon is Earth's only natural satellite.",
        "The Pacific Ocean is the largest ocean on Earth.",
        "Photosynthesis is the process by which green plants convert sunlight into energy.",
        "The human heart has four chambers: two atria and two ventricles.",
        "Mount Everest is the tallest mountain in the world.",
        "The Earth revolves around the sun once every 365.25 days.",
        "Light travels at a speed of approximately 299,792 kilometers per second.",
        "The Statue of Liberty was a gift from France to the United States.",
        "Bacteria are single-celled microorganisms that can be both harmful and beneficial.",
        "The internet was invented in the late 20th century.",
        "Electricity is the flow of electric charge through a conductor.",
        "The Taj Mahal is located in Agra, India.",
        "Google was founded by Larry Page and Sergey Brin.",
        "Albert Einstein developed the theory of relativity.",
        "The Amazon Rainforest is the largest tropical rainforest in the world.",
        "Bitcoin is a type of decentralized digital currency.",
        "A galaxy is a system of stars, gas, and dust bound together by gravity.",
        "Venus is the hottest planet in our solar system.",
        "The human body has 206 bones.",
        "HTML stands for HyperText Markup Language.",
        "Shakespeare wrote plays such as Hamlet, Macbeth, and Romeo and Juliet.",
        "COVID-19 is a disease caused by the SARS-CoV-2 virus.",
        "The brain is the control center of the human nervous system."
    ]
})

# üöÄ Load models
@st.cache_resource(show_spinner=False)
def load_models():
    embed_model = SentenceTransformer("all-MiniLM-L6-v2")
    qa_model = pipeline("text2text-generation", model="google/flan-t5-small")
    return embed_model, qa_model

embed_model, qa_model = load_models()

@st.cache_data(show_spinner=False)
def compute_embeddings():
    return np.vstack(df['content'].apply(lambda x: embed_model.encode(x)))

doc_embeddings = compute_embeddings()

# üîç Find most relevant context
def get_most_similar_doc(query):
    query_embedding = embed_model.encode(query)
    sims = cosine_similarity([query_embedding], doc_embeddings)[0]
    top_idx = np.argmax(sims)
    return df.iloc[top_idx]['content']

# üí¨ Chat session
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "bot", "text": "Hello! I'm your AI assistant. I can chat with you and generate images. What would you like to do today?"}
    ]

# üßæ Show chat messages
for msg in st.session_state.messages:
    avatar = "https://img.icons8.com/ios-filled/50/ffffff/user.png" if msg["role"] == "user" else "https://img.icons8.com/ios-filled/50/ffffff/robot-2.png"
    bubble_class = "user-bubble" if msg["role"] == "user" else "bot-bubble"
    st.markdown(f"""
        <div class='message-bubble {bubble_class}'>
            <img src="{avatar}" class="avatar">
            <div><b>{'You' if msg['role'] == 'user' else 'Bot'}:</b> {msg['text']}</div>
        </div>
    """, unsafe_allow_html=True)

# ‚úçÔ∏è Input box
query = st.text_input("Type your message...", key="input")

if query:
    st.session_state.messages.append({"role": "user", "text": query})
    context = get_most_similar_doc(query)
    prompt = f"Context: {context}\nQuestion: {query}"
    response = qa_model(prompt, max_new_tokens=100)[0]["generated_text"]
    st.session_state.messages.append({"role": "bot", "text": response})
    st.rerun()
